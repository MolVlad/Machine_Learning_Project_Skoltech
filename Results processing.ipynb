{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uw7bTjv37IED"
   },
   "outputs": [],
   "source": [
    "# Data processing tools: pandas and numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# Visualization\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.patches import Circle, RegularPolygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from matplotlib.projections import register_projection\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "\n",
    "# Others\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters description\n",
    "#### Noise mode\n",
    "- 0 - no noise\n",
    "- 1 - AWGN noise\n",
    "- 2 - replacements\n",
    "\n",
    "#### Dropping mode\n",
    "- 0 - no dropping\n",
    "- 1 - MCAR\n",
    "- 2 - MAR\n",
    "- 3 - NMAR\n",
    "\n",
    "#### Imputation mode\n",
    "- 0 - dropping\n",
    "- 1 - filling with 0\n",
    "- 2 - filling with mean\n",
    "- 3 - filling with median\n",
    "- 4 - filling by MICE\n",
    "- 5 - filling by kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_with_results = \"Results\"\n",
    "directory_with_graphs = \"Graphs\"\n",
    "\n",
    "# Create directory\n",
    "if not os.path.exists(directory_with_graphs):\n",
    "    os.mkdir(directory_with_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(model_number):\n",
    "    if model_number == 0:\n",
    "        return \"Linear\"\n",
    "    if model_number == 1:\n",
    "        return \"DT\"\n",
    "    if model_number == 2:\n",
    "        return \"RF\"\n",
    "    if model_number == 3:\n",
    "        return \"GB\"\n",
    "    \n",
    "def get_imputation_name(imputation_mode):\n",
    "    if imputation_mode == 1:\n",
    "        return \"Filling with 0\"\n",
    "    if imputation_mode == 2:\n",
    "        return \"Filling with mean\"\n",
    "    if imputation_mode == 3:\n",
    "        return \"Filling with median\"\n",
    "    if imputation_mode == 4:\n",
    "        return \"Filling by MICE\"\n",
    "    if imputation_mode == 5:\n",
    "        return \"Filling by KNN\"\n",
    "    \n",
    "def get_drop_name(drop_mode):\n",
    "    if drop_mode == 1:\n",
    "        return \"MCAR\"\n",
    "    if drop_mode == 2:\n",
    "        return \"MAR\"\n",
    "    if drop_mode == 3:\n",
    "        return \"NMAR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_radar(num_vars, frame = 'circle'):\n",
    "    # calculate evenly-spaced axis angles\n",
    "    theta = np.linspace(0, 2*np.pi, num_vars, endpoint = False)\n",
    "    \n",
    "    class RadarTransform(PolarAxes.PolarTransform):\n",
    "        def transform_path_non_affine(self, path):\n",
    "            if path._interpolation_steps > 1:\n",
    "                path = path.interpolated(num_vars)\n",
    "            return Path(self.transform(path.vertices), path.codes)\n",
    "\n",
    "    class AxesRadar(PolarAxes):\n",
    "\n",
    "        name = 'radar'\n",
    "        \n",
    "        PolarTransform = RadarTransform\n",
    "\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            # rotate plot such that the first axis is at the top\n",
    "            self.set_theta_zero_location('N')\n",
    "\n",
    "        def fill(self, *args, closed = True, **kwargs):\n",
    "            return super().fill(closed = closed, *args, **kwargs)\n",
    "\n",
    "        def plot(self, *args, **kwargs):\n",
    "            lines = super().plot(*args, **kwargs)\n",
    "            for line in lines:\n",
    "                self._close_line(line)\n",
    "\n",
    "        def _close_line(self, line):\n",
    "            x, y = line.get_data()\n",
    "            if x[0] != x[-1]:\n",
    "                x = np.concatenate((x, [x[0]]))\n",
    "                y = np.concatenate((y, [y[0]]))\n",
    "                line.set_data(x, y)\n",
    "\n",
    "        def set_varlabels(self, labels):\n",
    "            self.set_thetagrids(np.degrees(theta), labels)\n",
    "\n",
    "        def _gen_axes_patch(self):\n",
    "            # The Axes patch must be centered at (0.5, 0.5) and of radius 0.5\n",
    "            # in axes coordinates.\n",
    "            if frame == 'circle':\n",
    "                return Circle((0.5, 0.5), 0.5)\n",
    "            elif frame == 'polygon':\n",
    "                return RegularPolygon((0.5, 0.5), num_vars,\n",
    "                                      radius=.5, edgecolor=\"k\")\n",
    "            else:\n",
    "                raise ValueError(\"unknwn val 'frame': %s\" % frame)\n",
    "\n",
    "        def draw(self, renderer):\n",
    "            \"\"\" Draw. If frame is polygon, make gridlines polygon-shaped \"\"\"\n",
    "            if frame == 'polygon':\n",
    "                gridlines = self.yaxis.get_gridlines()\n",
    "                for gl in gridlines:\n",
    "                    gl.get_path()._interpolation_steps = num_vars\n",
    "            super().draw(renderer)\n",
    "\n",
    "\n",
    "        def _gen_axes_spines(self):\n",
    "            if frame == 'circle':\n",
    "                return super()._gen_axes_spines()\n",
    "            elif frame == 'polygon':\n",
    "                # spine_type must be 'left'/'right'/'top'/'bottom'/'circle'.\n",
    "                spine = Spine(axes = self,\n",
    "                              spine_type = 'circle',\n",
    "                              path = Path.unit_regular_polygon(num_vars))\n",
    "  \n",
    "                spine.set_transform(Affine2D().scale(.5).translate(.5, .5)\n",
    "                                    + self.transAxes)\n",
    "                return {'polar': spine}\n",
    "            else:\n",
    "                raise ValueError(\"unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "    register_projection(AxesRadar)\n",
    "    return theta\n",
    "\n",
    "def make_diagram(inputs, titles, fig_name):\n",
    "    data = [titles, ('', [])]\n",
    "    for key in inputs.keys():\n",
    "        data[1][1].append(inputs[key])\n",
    "    N = len(data[0])\n",
    "    theta = diag_radar(N, 'polygon')\n",
    "\n",
    "    vertices_labels = data.pop(0)\n",
    "    title, case_data = data[0]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (7, 7), subplot_kw = dict(projection = 'radar'))\n",
    "    fig.subplots_adjust(top = 0.9, bottom = 0.1)\n",
    "    \n",
    "    ax.set_title(title,  position = (0.5, 1.1), ha = 'center')\n",
    "\n",
    "    #For rgrids\n",
    "    keys = inputs.keys()\n",
    "    min_list = []\n",
    "    max_list = []\n",
    "    for key in keys:\n",
    "        min_list.append(min(inputs[key]))\n",
    "        max_list.append(max(inputs[key]))\n",
    "    a = min(min_list)    \n",
    "    b = max(max_list)\n",
    "    x1 = np.round(np.linspace(a, b, 5), 3)\n",
    "    ax.set_rgrids(x1)\n",
    "    \n",
    "    for key, d in zip(inputs.keys(), case_data):\n",
    "        line = ax.plot(theta, d, label = key)\n",
    "        ax.fill(theta, d, alpha = 0.2)\n",
    "        ax.set_varlabels(vertices_labels)\n",
    "\n",
    "    plt.legend(loc ='lower right')\n",
    "    fig.savefig(fig_name, dpi = 200)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with noise only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(directory_with_results+\"/results_noise_only.csv\")\n",
    "\n",
    "for dataset_number in results['Dataset number'].unique():\n",
    "    for regression in results['Is regression'].unique():\n",
    "        for noise_mode in results['Noise mode'].unique():\n",
    "            df = results.copy()\n",
    "            df = df[(df['Dataset number'] == dataset_number) & (df['Is regression'] == regression) &\\\n",
    "                   (df['Noise mode'] == noise_mode)]\n",
    "            \n",
    "            if df.shape[0] == 0:\n",
    "                continue\n",
    "            \n",
    "            for model_number in range(4):\n",
    "                val_score_name = \"Val score \"+str(model_number)\n",
    "                initial_val_score_name = \"Initial val score \"+str(model_number)\n",
    "                label = get_model_name(model_number)\n",
    "\n",
    "                df_y=pd.DataFrame(df['Noise level'])\n",
    "\n",
    "                if regression:\n",
    "                    df_y[\"y\"] = df[initial_val_score_name] / df[val_score_name]\n",
    "                else:\n",
    "                    df_y[\"y\"] = df[val_score_name] / df[initial_val_score_name]\n",
    "\n",
    "                df_y=df_y.groupby(\"Noise level\").agg(('mean','std'))\n",
    "\n",
    "                y=list(df_y.y['mean'])\n",
    "                y_err=list(df_y.y['std'])\n",
    "                x = list(df_y.index)\n",
    "\n",
    "                plt.errorbar(x, y, yerr=y_err, label=label)\n",
    "\n",
    "            if regression:\n",
    "                plt.ylabel(\"MAPE on initial / MAPE on distorted\")\n",
    "            else:\n",
    "                plt.ylabel(\"F1 on distorted / F1 on initial\")\n",
    "\n",
    "            if noise_mode == 1:\n",
    "                plt.xlabel(\"SNR, dB\")\n",
    "                name = \"_SNR\"\n",
    "                plt.gca().invert_xaxis()\n",
    "            else:\n",
    "                name = \"_p\"\n",
    "                plt.xlabel(\"Changing probability\")\n",
    "\n",
    "            plt.legend(loc='best')\n",
    "            plt.grid()\n",
    "\n",
    "            fig_name = 'noise_reg_' + str(int(regression)) + \\\n",
    "                    '_dataset_' + str(dataset_number) + name + '.png'\n",
    "\n",
    "            plt.savefig(directory_with_graphs+\"/\"+fig_name, transparent=True)\n",
    "            plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbS9_ub7G8zd"
   },
   "source": [
    "# Experiments with missing values only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(directory_with_results+\"/results_drop_only.csv\")\n",
    "\n",
    "for dataset_number in results['Dataset number'].unique():\n",
    "    for regression in results['Is regression'].unique():\n",
    "        for dropping_mode in results['Drop mode'].unique():\n",
    "            for model_number in range(4):\n",
    "                df = results.copy()\n",
    "\n",
    "                df = df[(df['Dataset number'] == dataset_number) & (df['Is regression'] == regression) &\\\n",
    "                       (df['Drop mode'] == dropping_mode)]\n",
    "                \n",
    "                if df.shape[0] == 0:\n",
    "                    continue\n",
    "                \n",
    "                val_score_name = \"Val score \"+str(model_number)\n",
    "                initial_val_score_name = \"Initial val score \"+str(model_number)\n",
    "\n",
    "                for imputation_mode in df['Imputation mode'].unique():\n",
    "                    label = get_imputation_name(imputation_mode)\n",
    "\n",
    "                    sub_df = df[df['Imputation mode'] == imputation_mode]\n",
    "\n",
    "                    df_y=pd.DataFrame(sub_df['Drop level'])\n",
    "\n",
    "                    if regression:\n",
    "                        df_y[\"y\"] = sub_df[initial_val_score_name] / sub_df[val_score_name]\n",
    "                    else:\n",
    "                        df_y[\"y\"] = sub_df[val_score_name] / sub_df[initial_val_score_name]\n",
    "\n",
    "                    df_y=df_y.groupby(\"Drop level\").agg(('mean','std'))\n",
    "\n",
    "                    y=list(df_y.y['mean'])\n",
    "                    y_err=list(df_y.y['std'])\n",
    "                    x = list(df_y.index)\n",
    "\n",
    "                    plt.errorbar(x, y, yerr=y_err, label=label)\n",
    "\n",
    "                if regression:\n",
    "                    plt.ylabel(\"MAPE on initial / MAPE on distorted\")\n",
    "                else:\n",
    "                    plt.ylabel(\"F1 on distorted / F1 on initial\")\n",
    "\n",
    "                plt.xlabel(\"Dropping probability\")\n",
    "\n",
    "                plt.legend(loc='best')\n",
    "                plt.grid()\n",
    "\n",
    "                fig_name = 'drop4model_reg_' + str(int(regression)) + \\\n",
    "                        '_dataset_' + str(dataset_number) + \\\n",
    "                        '_drop_'+str(dropping_mode)+'_model_'+str(model_number)+\\\n",
    "                        '.png'\n",
    "\n",
    "                plt.savefig(directory_with_graphs+\"/\"+fig_name, transparent=True)\n",
    "                plt.clf();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(directory_with_results+\"/results_drop_only.csv\")\n",
    "\n",
    "for dataset_number in results['Dataset number'].unique():\n",
    "    for regression in results['Is regression'].unique():\n",
    "        df = results.copy()\n",
    "\n",
    "        df = df[(df['Dataset number'] == dataset_number) & (df['Is regression'] == regression)]\n",
    "        \n",
    "        if df.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        for model_number in range(4):\n",
    "            if regression:\n",
    "                metrics = df[\"Initial val score \"+str(model_number)] / \\\n",
    "                    df[\"Val score \"+str(model_number)]\n",
    "\n",
    "            else:\n",
    "                metrics = df[\"Val score \"+str(model_number)] / \\\n",
    "                    df[\"Initial val score \"+str(model_number)]\n",
    "\n",
    "            df[\"Metrics \"+str(model_number)] = metrics\n",
    "            \n",
    "        df[\"Median metrics\"] = df.filter(regex=\"Metrics\").median(axis=1)\n",
    "        \n",
    "        inputs = {}\n",
    "\n",
    "        titles = []\n",
    "        for drop_mode in [1,2,3]:\n",
    "            for drop_level in [0.1, 0.2, 0.3]:\n",
    "                titles.append(get_drop_name(drop_mode)+f'({drop_level})')\n",
    "\n",
    "        for imputation_mode in df['Imputation mode'].unique():\n",
    "            sub_df = df[df['Imputation mode'] == imputation_mode]\n",
    "\n",
    "            values = []\n",
    "            for drop_mode in [1,2,3]:\n",
    "                for drop_level in [0.1, 0.2, 0.3]:\n",
    "                    values.append(sub_df[(sub_df[\"Drop mode\"] == drop_mode) & \\\n",
    "                                         (sub_df[\"Drop level\"] == drop_level)][\"Median metrics\"].mean())\n",
    "\n",
    "\n",
    "            inputs[get_imputation_name(imputation_mode)] = values\n",
    "\n",
    "        fig_name = 'drop_diagram_reg_' + str(int(regression)) + \\\n",
    "                '_dataset_' + str(dataset_number)+'.png'\n",
    "\n",
    "        make_diagram(inputs, titles, directory_with_graphs+\"/\"+fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbS9_ub7G8zd"
   },
   "source": [
    "# Experiments with missing values and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(directory_with_results+\"/results_noise_and_drop.csv\")\n",
    "\n",
    "for dataset_number in results['Dataset number'].unique():\n",
    "    for regression in results['Is regression'].unique():\n",
    "        for noise_mode in results['Noise mode'].unique():\n",
    "                for noise_level in results['Noise level'].unique():\n",
    "                    df = results.copy()\n",
    "\n",
    "                    df = df[(df['Dataset number'] == dataset_number) & (df['Is regression'] == regression) &\\\n",
    "                           (df['Noise mode'] == noise_mode) & (df['Noise level'] == noise_level)]\n",
    "\n",
    "                    if df.shape[0] == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    for model_number in range(4):\n",
    "                        if regression:\n",
    "                            metrics = df[\"Initial val score \"+str(model_number)] / \\\n",
    "                                df[\"Val score \"+str(model_number)]\n",
    "                                    \n",
    "                        else:\n",
    "                            metrics = df[\"Val score \"+str(model_number)] / \\\n",
    "                                df[\"Initial val score \"+str(model_number)]\n",
    "                        \n",
    "                        df[\"Metrics \"+str(model_number)] = metrics\n",
    "            \n",
    "                    df[\"Median metrics\"] = df.filter(regex=\"Metrics\").median(axis=1)\n",
    "\n",
    "                    inputs = {}\n",
    "\n",
    "                    titles = []\n",
    "                    for drop_mode in [1,2,3]:\n",
    "                        for drop_level in [0.1, 0.2, 0.3]:\n",
    "                            titles.append(get_drop_name(drop_mode)+f'({drop_level})')\n",
    "\n",
    "                    for imputation_mode in df['Imputation mode'].unique():\n",
    "                        sub_df = df[df['Imputation mode'] == imputation_mode]\n",
    "\n",
    "                        values = []\n",
    "                        for drop_mode in [1,2,3]:\n",
    "                            for drop_level in [0.1, 0.2, 0.3]:\n",
    "                                values.append(sub_df[(sub_df[\"Drop mode\"] == drop_mode) & \\\n",
    "                                                (sub_df[\"Drop level\"] == drop_level)][\"Median metrics\"].mean())\n",
    "\n",
    "\n",
    "                        inputs[get_imputation_name(imputation_mode)] = values\n",
    "\n",
    "                    fig_name = 'noisy_drop_diagram_reg_' + str(int(regression)) + \\\n",
    "                            '_dataset_' + str(dataset_number)+ \\\n",
    "                            '_noise_' + str(noise_mode) + '_' + str(noise_level) + '.png'\n",
    "\n",
    "                    make_diagram(inputs, titles, directory_with_graphs+\"/\"+fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "project_part_Stepan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
